#!/usr/bin/env python3
import fnmatch
import json
import os
from contextlib import contextmanager
from tempfile import NamedTemporaryFile, TemporaryDirectory

import imgtestlib as testlib

JOB_TEMPLATE = """
build/{distro}/{arch}/{image_type}/{config_name}:
  stage: test
  script:
    - sudo ./test/scripts/setup-osbuild-repo
    - sudo ./test/scripts/install-dependencies
    - {dl_container}
    - {start_container}
    - ./test/scripts/build-image "{distro}" "{image_type}" "{config}"
    - ./test/scripts/boot-image "{distro}" "{arch}" "{image_type}" "{image_path}"
    - ./test/scripts/upload-results "{distro}" "{image_type}" "{config}"
  extends: .terraform
  variables:
    RUNNER: aws/fedora-40-{arch}
    INTERNAL_NETWORK: "{internal}"
  needs:
    - pipeline: "$PARENT_PIPELINE_ID"
      job: generate-ostree-build-config-{distro}-{arch}
"""


def read_config_map():
    with open(testlib.CONFIG_MAP, "r", encoding="utf-8") as config_map_file:
        return json.load(config_map_file)


def matches(name: str, filters: list[str]) -> bool:
    return any(fnmatch.fnmatch(name, i) for i in filters)


def configs_with_deps(configs, distro=None, arch=None):
    """
    Return a config map with only the config files that have dependencies.
    Filter on distro and arch if specified.
    """
    with_deps: dict[str, str] = {}
    config_map_dir = os.path.abspath(os.path.dirname(testlib.CONFIG_MAP))
    for path, filters in configs.items():
        # load config and check if it requires a commit
        config_path = os.path.join(config_map_dir, path)
        with open(config_path, "r", encoding="utf-8") as config_file:
            data = json.load(config_file)
        if not data.get("depends"):
            continue

        # filter on distro and arch
        distro_filters = filters.get("distros", [])
        if distro_filters and distro and not matches(distro, distro_filters):
            continue
        arch_filters = filters.get("arches", [])
        if arch_filters and arch and not matches(arch, arch_filters):
            continue

        with_deps[config_path] = filters

    return with_deps


def gen_dependency_manifests(config_map, distro, arch, outputdir):
    """
    Generate manifests for the dependencies of the configs in config map. The function generates a temporary config map
    that maps each config that appears in a dependency to the dependency image type and runs gen-manifests with that
    config map.

    Returns a dictionary mapping manifest file name (without path) to the manifest data and its ID.
    """
    target = arch
    distros = None
    if distro:
        target = distro + "/" + arch
        distros = [distro]

    print(f"üóíÔ∏è Generating manifests for dependencies for {target}")
    dep_config_map: dict = {}  # config map for the dependencies
    gen_image_types = set()  # set of all the image types to generate manifests for

    # generate a config map for the dependencies
    for config_path in config_map.keys():
        with open(config_path, encoding="utf-8") as config_file:
            cfg = json.load(config_file)

        dep = cfg["depends"]
        image_type = dep["image-type"]

        # dependency config path can be relative to config_path: make it absolute
        configs_dir = os.path.abspath(os.path.dirname(config_path))
        dep_config_path = os.path.join(configs_dir, dep["config"])

        dep_image_types = dep_config_map.get(dep_config_path, {}).get("image-types", [])
        dep_image_types.append(image_type)
        dep_config_map[dep_config_path] = {"image-types": dep_image_types}
        gen_image_types.add(image_type)

    # write dependency configs to temporary file and use as input to gen-manifests
    with NamedTemporaryFile(mode="w") as tmpfile:
        json.dump(dep_config_map, tmpfile)
        tmpfile.flush()
        err = testlib.gen_manifests(outputdir, config_map=tmpfile.name,
                                    distros=distros, arches=[arch], images=gen_image_types)
    # print stderr in case there were errors or warnings about skipped configurations
    # but filter out the annoying ones
    stderr = err.decode().splitlines()
    for line in stderr:
        if "No match for group package" in line:
            continue
        if "Failed to load consumer certs" in line:
            continue
        print(line)

    print("‚úÖ Manifest generation done!\n")
    return testlib.read_manifests(outputdir)


def gen_image_manifests(config_map, configs, distro, arch, outputdir):
    """
    Write the config map and configs to a temporary directory and generate the corresponding manifests in the output
    directory. The manifest generation skips any distro + arch + image-type configuration that isn't covered by the
    config map.

    Returns a dictionary mapping manifest file name (without path) to the manifest data and its ID.
    """
    target = arch
    distros = None
    if distro:
        target = distro + "/" + arch
        distros = [distro]

    print(f"üóíÔ∏è Generating manifests for ostree-based images for {target}")
    with TemporaryDirectory() as tmpdir:
        # write each config to a separate file
        for config in configs.values():
            with open(os.path.join(tmpdir, config["name"] + ".json"), "w", encoding="utf-8") as config_file:
                json.dump(config, config_file)

        # write config map in the same dir
        config_map_path = os.path.join(tmpdir, "config-map.json")
        with open(config_map_path, "w", encoding="utf-8") as config_map_file:
            json.dump(config_map, config_map_file)

        err = testlib.gen_manifests(outputdir, config_map=config_map_path,
                                    arches=[arch], distros=distros, commits=True, skip_no_config=True)

    # print stderr in case there were errors or warnings about skipped configurations
    # but filter out the annoying ones
    stderr = err.decode().splitlines()
    for line in stderr:
        if "No match for group package" in line:
            continue
        if "Failed to load consumer certs" in line:
            continue
        print(line)

    print("‚úÖ Manifest generation done!\n")
    return testlib.read_manifests(outputdir)


def default_ref(distro, arch):
    name, version = distro.split("-")
    if name == "rhel":
        # we use dots in our RHEL versions now
        version, *_ = version.split(".")
        product = "edge"
    elif name == "fedora":
        product = "iot"
    elif name == "centos":
        product = "edge"
    else:
        raise ValueError(f"unknown distro name {name}")

    return f"{name}/{version}/{arch}/{product}"     # pylint: disable=possibly-used-before-assignment


@contextmanager
def setup_dependencies(manifests, config_map, distro, arch):
    # pylint: disable=too-many-statements
    """
    For each config in the config map, list all image configurations (distro, arch, image type) that it applies to and
    use the manifests to find the corresponding manifest IDs. Pull and run the corresponding dependency container from
    the registry and write a new config (and config map) that replaces the ostree options with the container URL and
    port.
    The config map and configs that function yields can be used to generate manifests with ostree commits resolved.
    The containers are stopped when the context exits.
    """
    container_ids = []
    new_config_map: dict[str, dict] = {}
    new_configs = {}
    container_configs = {}

    container_ports: dict[str, int] = {}
    for config_path, filters in config_map.items():
        with open(config_path, encoding="utf-8") as config_file:
            config_data = json.load(config_file)
        config_name = config_data["name"]

        # dependency config path is relative to config file
        dep_config_path = os.path.join(os.path.dirname(config_path), config_data["depends"]["config"])
        with open(dep_config_path, encoding="utf-8") as dep_config_file:
            dep_config_data = json.load(dep_config_file)
        dep_config_name = dep_config_data["name"]
        dep_image_type = config_data["depends"]["image-type"]

        # get all image configurations that this config applies to
        distros = filters.get("distros")
        if distro:
            distros = [distro]
        arches = [arch]
        image_configs = testlib.list_images(distros=distros,
                                            arches=arches,
                                            images=filters.get("image-types"))

        for image_config in image_configs:
            ic_distro = image_config["distro"]
            ic_arch = image_config["arch"]
            ic_image_type = image_config["image-type"]
            dep_build_name = testlib.gen_build_name(ic_distro, ic_arch, dep_image_type, dep_config_name)
            manifest_id = manifests[dep_build_name + ".json"]["id"]
            container_s3_prefix = testlib.gen_build_info_s3(distro, arch, manifest_id)
            container_s3_path = f"{container_s3_prefix}container/container.tar"

            # start each container once on an incremental port
            port = container_ports.get(container_s3_path)
            if not port:
                # Pulling and launching the container will fail if the specific container config was never built.  This
                # can happen if a dependency is specified that does not exist in the config-map.
                port = 42000 + len(container_ports)
                container_ports[container_s3_path] = port

            # modify image config with container address and ref
            config_name = config_data["name"]
            config_name = f"{config_name}-{port}"
            # get the ref from the current config, or compute the default if unset
            ref = config_data.get("options", {}).get("ostree", {}).get("ref", default_ref(ic_distro, ic_arch))
            new_config = {
                "name": config_name,
                "options": {
                    "ostree": {
                        "url": f"http://localhost:{port}/repo",
                        "ref": ref,
                    }
                },
                "blueprint": config_data.get("blueprint"),
            }
            new_configs[config_name] = new_config

            container_configs[config_name] = {
                "s3path": container_s3_path,
                "port": port,
            }

            config_fname = config_name + ".json"
            new_filters = new_config_map.get(config_fname, {"distros": [], "arches": [], "image-types": []})
            new_filters["distros"].append(ic_distro)
            new_filters["arches"].append(ic_arch)
            new_filters["image-types"].append(ic_image_type)
            new_config_map[config_fname] = new_filters

    try:
        for container_s3_path, port in container_ports.items():
            with TemporaryDirectory() as container_dir:
                print(f"‚¨áÔ∏è Downloading container archive from {container_s3_path}")
                container_archive = os.path.join(container_dir, "container.tar")
                testlib.runcmd_nc(["aws", "s3", "cp", "--no-progress", container_s3_path, container_archive])
                print(f"üì¶ Starting container oci-archive:{container_archive} {port}")
                cont_id, _ = testlib.runcmd(["podman", "run", "-d", "--rm", f"-p{port}:8080",
                                             f"oci-archive:{container_archive}"])
                container_ids.append(cont_id.strip().decode())

        yield new_config_map, new_configs, container_configs
    finally:
        if container_ids:
            print("üì¶ Stopping containers")
            out, _ = testlib.runcmd(["podman", "stop", " ".join(container_ids)])
            print(out.decode())


def generate_configs(build_requests, container_configs, pipeline_file, configs_dir):
    print(f"üß™ Generating dynamic pipelines for {len(build_requests)} builds")
    os.makedirs(configs_dir, exist_ok=True)
    for build in build_requests:
        distro = build["distro"]
        arch = build["arch"]
        image_type = build["image-type"]
        config = build["config"]

        config_name = config["name"]

        build_name = testlib.gen_build_name(distro, arch, image_type, config_name)
        image_path = f"./build/{build_name}"
        # generate script line to pull and start container
        container = container_configs[config_name]

        # write the config to the artifacts directory
        build_config_path = os.path.join(configs_dir, config_name + ".json")
        with open(build_config_path, "w", encoding="utf-8") as build_config_file:
            json.dump(config, build_config_file)

        container_s3_path = container["s3path"]
        container_port = container["port"]

        dl_container_cmd = f"aws s3 cp --no-progress {container_s3_path} container.tar"
        run_container_cmd = f"podman run -d --rm -p{container_port}:8080 oci-archive:container.tar"

        pipeline_file.write(JOB_TEMPLATE.format(distro=distro, arch=arch, image_type=image_type,
                                                config_name=config_name, config=build_config_path,
                                                dl_container=dl_container_cmd,
                                                start_container=run_container_cmd,
                                                internal="true" if "rhel" in distro else "false",
                                                image_path=image_path))
    print("‚úÖ DONE!")


def main():
    parser = testlib.clargs()
    parser.add_argument("build_configs", type=str, help="directory to write individual build configs")
    args = parser.parse_args()

    config_path = args.config
    configs_dir = args.build_configs
    distro = args.distro
    arch = args.arch

    testlib.check_config_names()

    config_map = configs_with_deps(read_config_map(), distro, arch)  # filtered config map: only configs with deps

    with TemporaryDirectory() as cache_root:
        dep_manifest_dir = os.path.join(cache_root, "dependencies")
        dep_manifests = gen_dependency_manifests(config_map, distro, arch, dep_manifest_dir)

        with setup_dependencies(dep_manifests, config_map, distro, arch) as (pull_config_map, pull_configs, containers):
            manifest_dir = os.path.join(cache_root, "manifests")
            manifests = gen_image_manifests(pull_config_map, pull_configs, distro, arch, manifest_dir)

        build_requests = testlib.filter_builds(manifests, distro=distro, arch=arch, skip_ostree_pull=False)

    with open(config_path, "w", encoding="utf-8") as config_file:
        if len(build_requests) == 0:
            print("‚ö´ No manifest changes detected. Generating null config.")
            config_file.write(testlib.NULL_CONFIG)
            return

        config_file.write(testlib.BASE_CONFIG)
        generate_configs(build_requests, containers, config_file, configs_dir)


if __name__ == "__main__":
    main()
