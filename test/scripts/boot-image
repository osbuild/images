#!/usr/bin/env python3
import argparse
import contextlib
import json
import os
import pathlib
import random
import shutil
import string
import subprocess
import textwrap
import uuid
from tempfile import TemporaryDirectory

import imgtestlib as testlib

from vmtest.util import get_free_port
from vmtest.vm import QEMU


BASE_TEST_SCRIPT = "test/scripts/check-host-config.sh"
WSL_TEST_SCRIPT = "test/scripts/wsl-entrypoint.bat"


def get_aws_config():
    return {
        "key_id": os.environ.get("AWS_ACCESS_KEY_ID"),
        "secret_key": os.environ.get("AWS_SECRET_ACCESS_KEY"),
        "bucket": os.environ.get("AWS_BUCKET"),
        "region": os.environ.get("AWS_REGION")
    }


def get_azure_config():
    return {
        "subscription": os.environ.get("AZURE_SUBSCRIPTION"),
        "tenant": os.environ.get("AZURE_TENANT"),
        "client_id": os.environ.get("AZURE_CLIENT_ID"),
        "client_secret": os.environ.get("AZURE_CLIENT_SECRET"),
        "resource_group": os.environ.get("AZURE_RESOURCE_GROUP"),
        "windows_snapshot": os.environ.get("AZURE_WINDOWS_SNAPSHOT"),
        "windows_ssh_privkey": os.environ.get("AZURE_WINDOWS_SSH_PRIVKEY"),
    }


@contextlib.contextmanager
def create_ssh_key(privkey_file = None, key_type = None):
    with TemporaryDirectory() as tmpdir:
        keypath = os.path.join(tmpdir, "testkey")
        ci_priv_key = os.environ.get("CI_PRIV_SSH_KEY")
        if privkey_file is not None:
            shutil.copyfile(privkey_file, keypath)
            os.chmod(keypath, 0o600)

            cmd = ["ssh-keygen", "-y", "-f", keypath]
            out, _ = testlib.runcmd(cmd)
            pubkey = out.decode()
            with open(keypath + ".pub", "w", encoding="utf-8") as pubkeyfile:
                pubkeyfile.write(pubkey)
        elif not key_type and ci_priv_key:
            # running in CI: use key from env
            with open(keypath, "w", encoding="utf-8") as keyfile:
                keyfile.write(ci_priv_key + "\n")
            os.chmod(keypath, 0o600)

            # get public key from priv key and write it out
            cmd = ["ssh-keygen", "-y", "-f", keypath]
            out, _ = testlib.runcmd(cmd)
            pubkey = out.decode()
            with open(keypath + ".pub", "w", encoding="utf-8") as pubkeyfile:
                pubkeyfile.write(pubkey)
        elif key_type == "rsa":
            cmd = ["ssh-keygen", "-t", "rsa", "-b", "2048", "-m", "pem", "-N", "", "-f", keypath]
            testlib.runcmd_nc(cmd)
        else:
            # create an ssh key pair with empty password
            cmd = ["ssh-keygen", "-t", "ecdsa", "-b", "256", "-m", "pem", "-N", "", "-f", keypath]
            testlib.runcmd_nc(cmd)

        yield keypath, keypath + ".pub"


@contextlib.contextmanager
def ensure_uncompressed(filepath):
    """
    If the file at the given path is compressed, decompress it and return the new file path.
    """
    base, ext = os.path.splitext(filepath)
    if ext == ".xz":
        print(f"Uncompressing {filepath}")
        # needs to run as root to set perms and ownership on uncompressed file
        testlib.runcmd_nc(["sudo", "unxz", "--verbose", "--keep", filepath])
        yield base
        # cleanup when done so the uncompressed file doesn't get uploaded to the build cache
        os.unlink(base)

    else:
        # we only do xz for now so it must be raw: return as is and hope for the best
        yield filepath


@contextlib.contextmanager
def make_cloud_init_iso(pubkey_path) -> pathlib.Path:
    ssh_key = pathlib.Path(pubkey_path).read_text(encoding="utf8").strip()
    with TemporaryDirectory() as tmpdir:
        user_data = pathlib.Path(tmpdir) / "user-data.yaml"
        user_data_content = textwrap.dedent(f"""\
        #cloud-config
        users:
          - name: root
            ssh_authorized_keys:
              - {ssh_key}
          - name: osbuild
            groups: [wheel]
            sudo: ALL=(ALL) NOPASSWD:ALL
            ssh_authorized_keys:
              - {ssh_key}
        """)
        user_data.write_text(user_data_content)
        meta_data = pathlib.Path(tmpdir) / "meta-data"
        meta_data.write_text('{"instance-id": "i-1234567890abcdef0"}')
        iso_path = pathlib.Path(tmpdir) / "cloud-init.iso"
        subprocess.check_call(
            ["cloud-localds", os.fspath(iso_path), user_data.name, meta_data.name],
            cwd=tmpdir,
        )
        yield iso_path


class CannotRunQemuTest(Exception):
    def __init__(self, skip_reason):
        super().__init__(skip_reason)
        self.skip_reason = skip_reason


def ensure_can_run_qemu_test(arch, image_path, config_file):
    """
    Check if the given image_path, config_file is capable of running a
    qemu based test. Will return a bool and a skip_reason.
    """
    # keep in sync with imagetestlib.py:CAN_BOOT_TEST
    if arch not in ["x86_64"]:
        raise CannotRunQemuTest(f"no qemu boot test support for {arch} yet")
    manifest_path = pathlib.Path(image_path).parent / "../manifest.json"
    manifest = json.loads(manifest_path.read_text(encoding="utf8"))
    # Note that this needs adjustment when we switch to librepo
    urls = [src["url"] for src in manifest["sources"]["org.osbuild.curl"]["items"].values()]
    if not any("ssh-server" in url for url in urls):
        # This can happen e.g. when an image is build with the
        # "minimal: true" customization.
        # We could use guestfs to inject keys, see PR#1995
        raise CannotRunQemuTest("no ssh-server in image")
    # We need jq in the image many images do not have it
    # (e.g. centos-9/rhel-9 with releasever config) so skip those too
    if not any("jq" in url for url in urls):
        raise CannotRunQemuTest("no jq package in image")
    # gather more data
    info_path = pathlib.Path(image_path).parent / "../info.json"
    info = json.loads(info_path.read_text(encoding="utf8"))
    config = json.loads(pathlib.Path(config_file).read_text(encoding="utf8"))
    customizations = config.get("blueprint", {}).get("customizations", {})
    if customizations.get("fips") and info.get("distro").startswith("fedora"):
        raise CannotRunQemuTest("fips on fedora is unstable, fails with e.g. dracut: FATAL: FIPS integrity test failed")
    # network-installer has a bunch of extra constraints
    if info.get("image-type") in ["network-installer", "everything-network-installer"]:
        # network install needs subscribed content but we cannot provide
        # that currently
        if info.get("distro") in ["rhel-10.1", "rhel-10.2"]:
            raise CannotRunQemuTest(
                "rhel network-installer tests have incomplete repos in nightly snapshot and won't install")
        match info.get("distro"):
            case name if name.startswith("fedora"):
                raise CannotRunQemuTest(
                    "fedora network-installer crashes in sshd, "
                    "see https://bugzilla.redhat.com/show_bug.cgi?id=2415883")
            case "centos-9":
                raise CannotRunQemuTest("centos-9 will not start an install and waits on source selection")
            case name if name.startswith("rhel-9"):
                raise CannotRunQemuTest("rhel-9 will not start an install and waits on source selection")


def qemu_cmd_scp_and_run(vm, cmd, privkey_path):
    # This is similar to what the other runners are doing but
    # it would be nice to find a better way, e.g. create a
    # bundle or compsoe a single script with the config
    # build-in/appended
    for arg in cmd:
        if os.path.exists(arg):
            vm.scp(arg, "/tmp/", user="osbuild", keyfile=privkey_path)
    vmcmd = ["/tmp/" + os.path.basename(arg) for arg in cmd]
    return vm.run(vmcmd, user="osbuild", keyfile=privkey_path)


def boot_qemu(arch, image_path, config_file):
    ensure_can_run_qemu_test(arch, image_path, config_file)
    cmd = [BASE_TEST_SCRIPT, config_file]
    with contextlib.ExitStack() as cm:
        uncompressed_image_path = cm.enter_context(ensure_uncompressed(image_path))
        (privkey_path, pubkey_path) = cm.enter_context(create_ssh_key())
        cloud_init_iso = cm.enter_context(make_cloud_init_iso(pubkey_path))
        with QEMU(uncompressed_image_path, arch=arch, cdrom=cloud_init_iso) as vm:
            qemu_cmd_scp_and_run(vm, cmd, privkey_path)


def boot_qemu_iso_no_unattended_support(arch, installer_iso_path, config_file):
    ensure_can_run_qemu_test(arch, installer_iso_path, config_file)
    # this is for ISOs that have no "unattneded" support in their blueprint,
    # manually create one and modify the ISO
    rootpw = "".join(
        random.choices(string.ascii_uppercase + string.digits, k=18))
    rhsm = ""
    rhsm_unregister = ""
    # this is too crude, use "distro" from info file
    if "rhel" in installer_iso_path:
        org_id = os.getenv("SUBSCRIPTION_ORG")
        activation_key = os.getenv("SUBSCRIPTION_ACTIVATION_KEY")
        if not org_id or not activation_key:
            raise CannotRunQemuTest("rhel unattended tests need SUBSCRIPTION_ORG and SUBSCRIPTION_ACTIVATION_KEY env")
        rhsm = f'rhsm --organization="{org_id}" --activation-key="{activation_key}"'
        rhsm_unregister = textwrap.dedent("""\
        # ensure we unregister after the install again, no need to keep the system registered
        # and show up in the inventory
        subscription-manager unregister
        """)
    with contextlib.ExitStack() as cm:
        tmpdir = cm.enter_context(TemporaryDirectory(dir="/var/tmp"))
        (privkey_path, pubkey_path) = cm.enter_context(create_ssh_key())
        pubkey = pathlib.Path(pubkey_path).read_text("utf8").strip()
        unattended_ks = pathlib.Path(tmpdir) / "ks.cfg"
        unattended_ks.write_text(textwrap.dedent(f"""\
        text --non-interactive
        zerombr
        clearpart --all --initlabel
        autopart --type=plain
        network --activate --onboot=on
        reboot --eject
        user --name=osbuild --group=wheel --shell=/bin/bash
        sshkey --username=osbuild "{pubkey}"
        rootpw {rootpw}
        {rhsm}
        eula --agree
        # better debug for the sshd failure
        bootloader --append="console=ttyS0 systemd.journald.forward_to_console=1"
        %post
        # workaround for centos-10 as it fails to start here and that causes issue
        # with out "check-host-config.sh" that expects a non-degraded boot
        systemctl mask mcelog.service || true
        {rhsm_unregister}
        %end
        """))
        new_installer_iso_path = pathlib.Path(tmpdir) / os.path.basename(installer_iso_path)
        subprocess.check_call(
            ["sudo", "mkksiso",
             # Note that we could add:
             #    systemd.journald.forward_to_console=1
             # here as well but it produces extrem amounts of logs
             # that exceeds the gitlab limit
             "-c", "console=ttyS0",
             "--ks", os.fspath(unattended_ks),
             os.fspath(installer_iso_path), new_installer_iso_path])
        return _boot_qemu_iso(arch, new_installer_iso_path, config_file, privkey_path)


def boot_qemu_iso(arch, installer_iso_path, config_file):
    ensure_can_run_qemu_test(arch, installer_iso_path, config_file)
    # We can only test the unattended-iso as the other configs require
    # interactive setup of the installer which we do not support in this
    # test-runner.
    config = json.loads(pathlib.Path(config_file).read_text(encoding="utf8"))
    if not config.get("blueprint", {}).get("customizations", {}).get("installer", {}).get("unattended"):
        raise CannotRunQemuTest("only unattended installs are supported")
    with contextlib.ExitStack() as cm:
        # The "unattended-iso" has the CI ssh key, so if we are running
        # in CI we can actually do a real image test. Sadly not locally
        # because we have no way to log into the installed disk in this
        # case, the CI ssh key is secret.
        privkey_path = None
        if os.environ.get("CI_PRIV_SSH_KEY"):
            (privkey_path, _) = cm.enter_context(create_ssh_key())
        return _boot_qemu_iso(arch, installer_iso_path, config_file, privkey_path)


def _boot_qemu_iso(arch, installer_iso_path, config_file, privkey_path):
    cmd = [BASE_TEST_SCRIPT, config_file]
    # we should pass console=ttyS0 to instaler os that we see install
    # progress on the serial console, in the meantime for interactive use
    # one cans set the OSBUILD_TEST_QEMU_GUI=1 environment
    with contextlib.ExitStack() as cm:
        # we need /var/tmp here as /tmp might be on a (small) tmpfs
        tmpdir = cm.enter_context(TemporaryDirectory(dir="/var/tmp"))
        # create an (empty) target disk, truncate ensures its sparse
        # so it will not take up real disk space until things are
        # written to it
        test_disk_path = pathlib.Path(tmpdir) / "disk.img"
        with open(test_disk_path, "w", encoding="utf8") as fp:
            fp.truncate(20_000_000_000)
        # boot from installer to install to test disk, anaconda will
        # reboot automatically for the unattended-iso config.
        with QEMU(test_disk_path, cdrom=installer_iso_path) as vm:
            vm.start(wait_event="qmp:RESET", snapshot=False, use_ovmf=True)
            vm.force_stop()
        # now boot test disk and wait for ssh to come up as a minimal boot test
        with QEMU(test_disk_path, arch=arch) as vm:
            vm.start(use_ovmf=True)
            vm.wait_ssh_ready()
            if privkey_path:
                qemu_cmd_scp_and_run(vm, cmd, privkey_path)


def boot_qemu_pxe(arch, pxe_tar_path):
    with contextlib.ExitStack() as cm:
        # unpack the tar and create a combined image
        tmpdir = cm.enter_context(TemporaryDirectory(dir="/var/tmp"))
        subprocess.check_call(
            ["tar", "-C", tmpdir, "-x", "-f", pxe_tar_path])
        subprocess.check_call(
            "echo rootfs.img | cpio -c --quiet -L -o > rootfs.cpio", shell=True, cwd=tmpdir)
        subprocess.check_call(
            "cat initrd.img rootfs.cpio > combined.img", shell=True, cwd=tmpdir)

        # start an HTTP server to serve the rootfs.img
        http_port = get_free_port()
        with subprocess.Popen(
            ["python3", "-m", "http.server", f"{http_port}"],
            cwd=tmpdir,
            # prevent blocking output
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        ):
            # test disk is unused for live OS
            test_disk_path = pathlib.Path(tmpdir) / "disk.img"
            with open(test_disk_path, "w", encoding="utf-8") as fp:
                fp.truncate(0)

            # test both the combined and HTTP rootfs variants
            for use_ovmf in [False, True]:
                for root_arg, initrd_file in [
                    ("live:/rootfs.img", "combined.img"),
                    (f"live:http://10.0.2.2:{http_port}/rootfs.img", "initrd.img")
                ]:
                    append_arg = (
                        f"rd.live.image root={root_arg} console=ttyS0 "
                        f"systemd.debug-shell=ttyS0 "
                        f"systemd.mask=serial-getty@ttyS0.service "
                        f"systemd.unit=reboot.target"
                    )
                    extra_args = [
                        "-kernel", str(pathlib.Path(tmpdir) / "vmlinuz"),
                        "-initrd", str(pathlib.Path(tmpdir) / initrd_file),
                        "-append", append_arg
                    ]

                    with QEMU(test_disk_path, memory="3000", arch=arch, extra_args=extra_args) as vm:
                        # Wait for QMP RESET event instead of SSH since PXE images don't have SSH.
                        # The systemd.unit=reboot.target will cause a reboot, triggering the RESET event.
                        vm.start(wait_event="qmp:RESET", snapshot=False, use_ovmf=use_ovmf)
                        # There is really very little in the rootfs.img (i.e. no ssh, cloud-init
                        # or other things that open ports or dnf) and we can only control it via the
                        # kernel commandline. So via the "systemd.unit=reboot.target" kernel commandline
                        # above we boot and then force a reboot right away as our test. This is not great
                        # but the best we can do right now. Other options:
                        # 1. have a blueprint with sshd-server so that we can check for ssh port
                        # 2. modify vm.py to be able to talk directly to the serial console
                        #    and then run commands directly via that
                        vm.force_stop()


def cmd_boot_aws(arch, image_name, privkey, pubkey, image_path, script_cmd):
    # pylint: disable=too-many-arguments,too-many-positional-arguments
    aws_config = get_aws_config()
    cmd = ["go", "run", "./cmd/boot-aws", "run",
           "--access-key-id", aws_config["key_id"],
           "--secret-access-key", aws_config["secret_key"],
           "--region", aws_config["region"],
           "--bucket", aws_config["bucket"],
           "--arch", arch,
           "--ami-name", image_name,
           "--s3-key", f"images/boot/{image_name}",
           "--username", "osbuild",
           "--ssh-privkey", privkey,
           "--ssh-pubkey", pubkey,
           image_path, *script_cmd]
    testlib.runcmd_nc(cmd)


def boot_ami(distro, arch, image_type, image_path, config):
    cmd = [BASE_TEST_SCRIPT, config]
    with ensure_uncompressed(image_path) as raw_image_path:
        with create_ssh_key() as (privkey, pubkey):
            image_name = f"image-boot-test-{distro}-{arch}-{image_type}-" + str(uuid.uuid4())
            cmd_boot_aws(arch, image_name, privkey, pubkey, raw_image_path, cmd)


def boot_container(distro, arch, image_type, image_path, manifest_id):
    """
    Use bootc-image-builder to build an AMI and boot it.
    """
    # push container to registry so we can build it with BIB
    # remove when BIB can pull from containers-storage: https://github.com/osbuild/bootc-image-builder/pull/120
    container_name = f"iot-bootable-container:{distro}-{arch}-{manifest_id}"
    cmd = ["./tools/ci/push-container.sh", image_path, container_name]
    testlib.runcmd_nc(cmd)
    container_ref = f"{testlib.REGISTRY}/{container_name}"

    with TemporaryDirectory() as tmpdir:
        with create_ssh_key() as (privkey_file, pubkey_file):
            with open(pubkey_file, encoding="utf-8") as pubkey_fp:
                pubkey = pubkey_fp.read()

            # write a config to create a user
            config_file = os.path.join(tmpdir, "config.json")
            with open(config_file, "w", encoding="utf-8") as cfg_fp:
                config = {
                    "blueprint": {
                        "customizations": {
                            "user": [
                                {
                                    "name": "osbuild",
                                    "key": pubkey,
                                    "groups": [
                                        "wheel"
                                    ]
                                }
                            ]
                        }
                    }
                }
                json.dump(config, cfg_fp)

            # build an AMI
            cmd = ["sudo", "podman", "run",
                   "--rm", "-it",
                   "--privileged",
                   "--pull=newer",
                   "--security-opt", "label=type:unconfined_t",
                   "-v", f"{tmpdir}:/output",
                   "-v", f"{config_file}:/config.json",
                   testlib.get_bib_ref(),
                   "--type=ami",
                   "--config=/config.json",
                   container_ref]
            testlib.runcmd_nc(cmd)

            # boot it
            image_name = f"image-boot-test-{distro}-{arch}-{image_type}-" + str(uuid.uuid4())

            # Build artifacts are owned by root. Make them world accessible.
            testlib.runcmd(["sudo", "chmod", "a+rwX", "-R", tmpdir])
            raw_image_path = f"{tmpdir}/image/disk.raw"
            cmd_boot_aws(arch, image_name, privkey_file, pubkey_file, raw_image_path, [BASE_TEST_SCRIPT])


def boot_vhd(distro, arch, image_path, config):
    cmd = [BASE_TEST_SCRIPT, config]
    with ensure_uncompressed(image_path) as raw_image_path:
        with create_ssh_key(key_type="rsa") as (privkey, pubkey):
            # a lot of resources have <=64 character naming constraint
            name = f"{distro}-" + str(uuid.uuid4())

            # pylint: disable=too-many-arguments,too-many-positional-arguments
            az_config = get_azure_config()
            cmd = ["go", "run", "./cmd/boot-azure", "run",
                   "--subscription", az_config["subscription"],
                   "--tenant", az_config["tenant"],
                   "--client-id", az_config["client_id"],
                   "--client-secret", az_config["client_secret"],
                   "--resource-group", az_config["resource_group"],
                   "--username", "osbuild",
                   "--ssh-privkey", privkey,
                   "--ssh-pubkey", pubkey,
                   "--vm-name", name,
                   "--arch", arch,
                   "--image-name", name,
                   raw_image_path, *cmd]
            testlib.runcmd_nc(cmd)


def boot_wsl(distro, arch, image_path, config):
    with ensure_uncompressed(image_path) as raw_image_path:
        cmd = [WSL_TEST_SCRIPT, raw_image_path, BASE_TEST_SCRIPT, config]
        # pylint: disable=too-many-arguments,too-many-positional-arguments
        az_config = get_azure_config()
        with create_ssh_key(privkey_file = az_config["windows_ssh_privkey"]) as (privkey, pubkey):
            # a lot of resources have <=64 character naming constraint
            name = f"{distro}-" + str(uuid.uuid4())

            cmd = ["go", "run", "./cmd/boot-azure", "run",
                   "--subscription", az_config["subscription"],
                   "--tenant", az_config["tenant"],
                   "--client-id", az_config["client_id"],
                   "--client-secret", az_config["client_secret"],
                   "--resource-group", az_config["resource_group"],
                   "--snapshot", az_config["windows_snapshot"],
                   "--username", "azureuser",
                   "--ssh-privkey", privkey,
                   "--ssh-pubkey", pubkey,
                   "--vm-name", name,
                   "--arch", arch,
                   "--size", "Standard_D2as_v5",
                   raw_image_path, *cmd]
            testlib.runcmd_nc(cmd)


def main():
    desc = "Boot an image in the cloud environment it is built for and validate the configuration"
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("image_search_path", type=str, help="path to search for image file")

    args = parser.parse_args()
    search_path = args.image_search_path

    image_path = testlib.find_image_file(search_path)
    build_info = testlib.read_build_info(search_path)
    build_config_name = build_info["config"]
    build_config_path = f"test/configs/{build_config_name}.json"
    distro = build_info["distro"]
    arch = build_info["arch"]
    image_type = build_info["image-type"]

    print(f"Testing image at {image_path}")
    bib_image_id = ""
    # Keep test/scripts/imagetestlib.py:CAN_BOOT_TEST in sync as it
    # has the same checks again
    # WARNING: skipping boot tests that are listed under CAN_BOOT_TEST will cause the skipped image configuration to be
    # rebuilt every CI run.
    match image_type:
        # Not all qcow2 types can be boot-tested, for example `server-qcow2` uses
        # initial-setup and this blocks the boot.
        case "qcow2" | "generic-qcow2" | "cloud-qcow2":
            try:
                boot_qemu(arch, image_path, build_config_path)
            except CannotRunQemuTest as e:
                print(f"WARNING: skipping {image_path}: {e.skip_reason}")
                return
        case "image-installer" | "minimal-installer":
            try:
                boot_qemu_iso(arch, image_path, build_config_path)
            except CannotRunQemuTest as e:
                print(f"WARNING: skipping iso {image_path}: {e.skip_reason}")
                return
        case "network-installer" | "everything-network-installer":
            try:
                boot_qemu_iso_no_unattended_support(arch, image_path, build_config_path)
            except CannotRunQemuTest as e:
                print(f"WARNING: skipping iso {image_path}: {e.skip_reason}")
                return
        case "pxe-tar-xz":
            boot_qemu_pxe(arch, image_path)
        case "ami" | "ec2" | "ec2-ha" | "ec2-sap" | "edge-ami" | "cloud-ec2":
            boot_ami(distro, arch, image_type, image_path, build_config_path)
        case "vhd":
            boot_vhd(distro, arch, image_path, build_config_path)
        case "iot-bootable-container":
            manifest_id = build_info["manifest-checksum"]
            boot_container(distro, arch, image_type, image_path, manifest_id)
            bib_ref = testlib.get_bib_ref()
            bib_image_id = testlib.skopeo_inspect_id(f"docker://{bib_ref}", testlib.host_container_arch())
        case "wsl" | "generic-wsl":
            if distro == "fedora-41":
                print(f"{distro} {image_type} boot tests are not supported, fails on wsl import")
                return
            boot_wsl(distro, arch, image_path, build_config_path)
        case _:
            # skip
            print(f"{image_type} boot tests are not supported yet")
            return

    print("âœ… Marking boot successful")
    # amend build info with boot success
    # search_path is the root of the build path (build/build_name)
    build_info["boot-success"] = True
    testlib.write_build_info(search_path, build_info)
    if bib_image_id:
        # write a separate file with the bib image ID as filename to mark the boot success with that image
        bib_id_file = os.path.join(search_path, f"bib-{bib_image_id}")
        print(f"Writing bib image ID file: {bib_id_file}")
        with open(bib_id_file, "w", encoding="utf-8") as fp:
            fp.write("")


if __name__ == "__main__":
    main()
