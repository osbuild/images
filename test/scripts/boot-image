#!/usr/bin/env python3
import argparse
import contextlib
import json
import os
import pathlib
import uuid
import subprocess
import shlex
import shutil
import textwrap
from tempfile import TemporaryDirectory

import imgtestlib as testlib
from vmtest.vm import QEMU

BASE_TEST_SCRIPT = "test/scripts/check-host-config.sh"
WSL_TEST_SCRIPT = "test/scripts/wsl-entrypoint.bat"


def get_aws_config():
    return {
        "key_id": os.environ.get("AWS_ACCESS_KEY_ID"),
        "secret_key": os.environ.get("AWS_SECRET_ACCESS_KEY"),
        "bucket": os.environ.get("AWS_BUCKET"),
        "region": os.environ.get("AWS_REGION")
    }


def get_azure_config():
    return {
        "subscription": os.environ.get("AZURE_SUBSCRIPTION"),
        "tenant": os.environ.get("AZURE_TENANT"),
        "client_id": os.environ.get("AZURE_CLIENT_ID"),
        "client_secret": os.environ.get("AZURE_CLIENT_SECRET"),
        "resource_group": os.environ.get("AZURE_RESOURCE_GROUP"),
        "windows_snapshot": os.environ.get("AZURE_WINDOWS_SNAPSHOT"),
        "windows_ssh_privkey": os.environ.get("AZURE_WINDOWS_SSH_PRIVKEY"),
    }


@contextlib.contextmanager
def create_ssh_key(privkey_file = None, key_type = None):
    with TemporaryDirectory() as tmpdir:
        keypath = os.path.join(tmpdir, "testkey")
        ci_priv_key = os.environ.get("CI_PRIV_SSH_KEY_2")
        if privkey_file is not None:
            shutil.copyfile(privkey_file, keypath)
            os.chmod(keypath, 0o600)

            cmd = ["ssh-keygen", "-y", "-f", keypath]
            out, _ = testlib.runcmd(cmd)
            pubkey = out.decode()
            with open(keypath + ".pub", "w", encoding="utf-8") as pubkeyfile:
                pubkeyfile.write(pubkey)
        elif not key_type and ci_priv_key:
            # running in CI: use key from env
            with open(keypath, "w", encoding="utf-8") as keyfile:
                keyfile.write(ci_priv_key + "\n")
            os.chmod(keypath, 0o600)

            # get public key from priv key and write it out
            cmd = ["ssh-keygen", "-y", "-f", keypath]
            out, _ = testlib.runcmd(cmd)
            pubkey = out.decode()
            with open(keypath + ".pub", "w", encoding="utf-8") as pubkeyfile:
                pubkeyfile.write(pubkey)
        elif key_type == "rsa":
            cmd = ["ssh-keygen", "-t", "rsa", "-b", "2048", "-m", "pem", "-N", "", "-f", keypath]
            testlib.runcmd_nc(cmd)
        else:
            # create an ssh key pair with empty password
            cmd = ["ssh-keygen", "-t", "ecdsa", "-b", "256", "-m", "pem", "-N", "", "-f", keypath]
            testlib.runcmd_nc(cmd)

        yield keypath, keypath + ".pub"


@contextlib.contextmanager
def ensure_uncompressed(filepath):
    """
    If the file at the given path is compressed, decompress it and return the new file path.
    """
    base, ext = os.path.splitext(filepath)
    if ext == ".xz":
        print(f"Uncompressing {filepath}")
        # needs to run as root to set perms and ownership on uncompressed file
        testlib.runcmd_nc(["sudo", "unxz", "--verbose", "--keep", filepath])
        yield base
        # cleanup when done so the uncompressed file doesn't get uploaded to the build cache
        os.unlink(base)

    else:
        # we only do xz for now so it must be raw: return as is and hope for the best
        yield filepath


@contextlib.contextmanager
def make_cloud_init_iso(pubkey_path) -> pathlib.Path:
    ssh_key = pathlib.Path(pubkey_path).read_text(encoding="utf8").strip()
    with TemporaryDirectory() as tmpdir:
        user_data = pathlib.Path(tmpdir) / "user-data.yaml"
        user_data_content = textwrap.dedent(f"""\
        #cloud-config
        users:
          - name: root
            ssh_authorized_keys:
              - {ssh_key}
        """)
        user_data.write_text(user_data_content)
        meta_data = pathlib.Path(tmpdir) / "meta-data"
        meta_data.write_text('{"instance-id": "i-1234567890abcdef0"}')
        iso_path = pathlib.Path(tmpdir) / "cloud-init.iso"
        subprocess.check_call(
            ["cloud-localds", os.fspath(iso_path), user_data.name, meta_data.name],
            cwd=tmpdir,
        )
        yield iso_path


class CannotRunQemuTest(Exception):
    def __init__(self, skip_reason):
        super().__init__(skip_reason)
        self.skip_reason = skip_reason


def ensure_can_run_qemu_test(arch, image_path, config_file):
    """
    Check if the given image_path, config_file is capable of running a
    qemu based test. Will return a bool and a skip_reason.
    """
    # keep in sync with imagetestlib.py:CAN_BOOT_TEST
    if arch not in ["x86_64"]:
        raise CannotRunQemuTest(f"no qemu boot test support for {arch} yet")
    manifest_path = pathlib.Path(image_path).parent / "../manifest.json"
    manifest = json.loads(manifest_path.read_text(encoding="utf8"))
    # Note that this needs adjustment when we switch to librepo
    urls = [src["url"] for src in manifest["sources"]["org.osbuild.curl"]["items"].values()]
    if not any("ssh-server" in url for url in urls):
        # This can happen e.g. when an image is build with the
        # "minimal: true" customization.
        # We could use guestfs to inject keys, see PR#1995
        raise CannotRunQemuTest("no ssh-server in image")
    # We need jq in the image many images do not have it
    # (e.g. centos-9/rhel-9 with releasever config) so skip those too
    if not any("jq" in url for url in urls):
        raise CannotRunQemuTest("no jq package in image")
    # We cannot test openscap right now, its unclear why, we get a permission denied
    # from the root login
    config = json.loads(pathlib.Path(config_file).read_text(encoding="utf8"))
    customizations = config.get("blueprint", {}).get("customizations", {})
    if "openscap" in customizations:
        raise CannotRunQemuTest("openscap is not working right now")


def qemu_cmd_scp_and_run(vm, cmd, privkey_path):
    # This is similar to what the other runners are doing but
    # it would be nice to find a better way, e.g. create a
    # bundle or compsoe a single script with the config
    # build-in/appended
    for arg in cmd:
        if os.path.exists(arg):
            vm.scp(arg, "/tmp/", user="root", keyfile=privkey_path)
    vmcmd = shlex.join(["/tmp/" + os.path.basename(arg) for arg in cmd])
    return vm.run(vmcmd, user="root", keyfile=privkey_path)


def boot_qemu(arch, image_path, config_file):
    try:
        ensure_can_run_qemu_test(arch, image_path, config_file)
    except CannotRunQemuTest as e:
        print(f"WARNING: skipping {image_path}: {e.skip_reason}")
        return
    cmd = [BASE_TEST_SCRIPT, config_file]
    with contextlib.ExitStack() as cm:
        uncompressed_image_path = cm.enter_context(ensure_uncompressed(image_path))
        (privkey_path, pubkey_path) = cm.enter_context(create_ssh_key())
        cloud_init_iso = cm.enter_context(make_cloud_init_iso(pubkey_path))
        with QEMU(uncompressed_image_path, arch=arch, cdrom=cloud_init_iso) as vm:
            exit_status, _ = qemu_cmd_scp_and_run(vm, cmd, privkey_path)
            assert exit_status == 0


def boot_qemu_iso(arch, installer_iso_path, config_file):
    try:
        ensure_can_run_qemu_test(arch, installer_iso_path, config_file)
    except CannotRunQemuTest as e:
        print(f"WARNING: skipping {installer_iso_path} with {config_file}: {e.skip_reason}")
        return
    config = json.loads(pathlib.Path(config_file).read_text(encoding="utf8"))
    # We can only test the unattended-iso as the other configs require
    # interactive setup of the installer which we do not support in this
    # test-runner.
    if not config.get("blueprint", {}).get("customizations", {}).get("installer", {}).get("unattended"):
        print("WARNING: skipping {installer_iso_path} with {config_file}: only unattended installs are supported")
        return
    cmd = [BASE_TEST_SCRIPT, config_file]
    # we should pass console=ttyS0 to instaler os that we see install
    # progress on the serial console, in the meantime for interactive use
    # one cans set the OSBUILD_TEST_QEMU_GUI=1 environment
    with contextlib.ExitStack() as cm:
        # we need /var/tmp here as /tmp might be on a (small) tmpfs
        tmpdir = cm.enter_context(TemporaryDirectory(dir="/var/tmp"))
        # create an (empty) target disk, truncate ensures its sparse
        # so it will not take up real disk space until things are
        # written to it
        test_disk_path = pathlib.Path(tmpdir) / "disk.img"
        with open(test_disk_path, "w", encoding="utf8") as fp:
            fp.truncate(10_000_000_000)
        # boot from installer to install to test disk, anaconda will
        # reboot automatically for the unattended-iso config.
        with QEMU(test_disk_path, cdrom=installer_iso_path) as vm:
            vm.start(wait_event="qmp:RESET", snapshot=False, use_ovmf=True)
            vm.force_stop()
        # now boot test disk and wait for ssh to come up as a minimal boot test
        with QEMU(test_disk_path) as vm:
            vm.start(use_ovmf=True)
            vm.wait_ssh_ready()
            # The "unattended-iso" has the CI ssh key, so if we are running
            # in CI we can actually do a real image test. Sadly not locally
            # because we have no way to log into the installed disk in this
            # case, the CI ssh key is secret.
            if os.environ.get("CI_PRIV_SSH_KEY_2"):
                with create_ssh_key() as (privkey_path, _):
                    exit_status, _ = qemu_cmd_scp_and_run(vm, cmd, privkey_path)
                    assert exit_status == 0


def cmd_boot_aws(arch, image_name, privkey, pubkey, image_path, script_cmd):
    # pylint: disable=too-many-arguments,too-many-positional-arguments
    aws_config = get_aws_config()
    cmd = ["go", "run", "./cmd/boot-aws", "run",
           "--access-key-id", aws_config["key_id"],
           "--secret-access-key", aws_config["secret_key"],
           "--region", aws_config["region"],
           "--bucket", aws_config["bucket"],
           "--arch", arch,
           "--ami-name", image_name,
           "--s3-key", f"images/boot/{image_name}",
           "--username", "osbuild",
           "--ssh-privkey", privkey,
           "--ssh-pubkey", pubkey,
           image_path, *script_cmd]
    testlib.runcmd_nc(cmd)


def boot_ami(distro, arch, image_type, image_path, config):
    cmd = [BASE_TEST_SCRIPT, config]
    with ensure_uncompressed(image_path) as raw_image_path:
        with create_ssh_key() as (privkey, pubkey):
            image_name = f"image-boot-test-{distro}-{arch}-{image_type}-" + str(uuid.uuid4())
            cmd_boot_aws(arch, image_name, privkey, pubkey, raw_image_path, cmd)


def boot_container(distro, arch, image_type, image_path, manifest_id):
    """
    Use bootc-image-builder to build an AMI and boot it.
    """
    # push container to registry so we can build it with BIB
    # remove when BIB can pull from containers-storage: https://github.com/osbuild/bootc-image-builder/pull/120
    container_name = f"iot-bootable-container:{distro}-{arch}-{manifest_id}"
    cmd = ["./tools/ci/push-container.sh", image_path, container_name]
    testlib.runcmd_nc(cmd)
    container_ref = f"{testlib.REGISTRY}/{container_name}"

    with TemporaryDirectory() as tmpdir:
        with create_ssh_key() as (privkey_file, pubkey_file):
            with open(pubkey_file, encoding="utf-8") as pubkey_fp:
                pubkey = pubkey_fp.read()

            # write a config to create a user
            config_file = os.path.join(tmpdir, "config.json")
            with open(config_file, "w", encoding="utf-8") as cfg_fp:
                config = {
                    "blueprint": {
                        "customizations": {
                            "user": [
                                {
                                    "name": "osbuild",
                                    "key": pubkey,
                                    "groups": [
                                        "wheel"
                                    ]
                                }
                            ]
                        }
                    }
                }
                json.dump(config, cfg_fp)

            # build an AMI
            cmd = ["sudo", "podman", "run",
                   "--rm", "-it",
                   "--privileged",
                   "--pull=newer",
                   "--security-opt", "label=type:unconfined_t",
                   "-v", f"{tmpdir}:/output",
                   "-v", f"{config_file}:/config.json",
                   testlib.get_bib_ref(),
                   "--type=ami",
                   "--config=/config.json",
                   container_ref]
            testlib.runcmd_nc(cmd)

            # boot it
            image_name = f"image-boot-test-{distro}-{arch}-{image_type}-" + str(uuid.uuid4())

            # Build artifacts are owned by root. Make them world accessible.
            testlib.runcmd(["sudo", "chmod", "a+rwX", "-R", tmpdir])
            raw_image_path = f"{tmpdir}/image/disk.raw"
            cmd_boot_aws(arch, image_name, privkey_file, pubkey_file, raw_image_path, [BASE_TEST_SCRIPT])


def boot_vhd(distro, arch, image_path, config):
    cmd = [BASE_TEST_SCRIPT, config]
    with ensure_uncompressed(image_path) as raw_image_path:
        with create_ssh_key(key_type="rsa") as (privkey, pubkey):
            # a lot of resources have <=64 character naming constraint
            name = f"{distro}-" + str(uuid.uuid4())

            # pylint: disable=too-many-arguments,too-many-positional-arguments
            az_config = get_azure_config()
            cmd = ["go", "run", "./cmd/boot-azure", "run",
                   "--subscription", az_config["subscription"],
                   "--tenant", az_config["tenant"],
                   "--client-id", az_config["client_id"],
                   "--client-secret", az_config["client_secret"],
                   "--resource-group", az_config["resource_group"],
                   "--username", "osbuild",
                   "--ssh-privkey", privkey,
                   "--ssh-pubkey", pubkey,
                   "--vm-name", name,
                   "--arch", arch,
                   "--image-name", name,
                   raw_image_path, *cmd]
            testlib.runcmd_nc(cmd)


def boot_wsl(distro, arch, image_path, config):
    with ensure_uncompressed(image_path) as raw_image_path:
        cmd = [WSL_TEST_SCRIPT, raw_image_path, BASE_TEST_SCRIPT, config]
        # pylint: disable=too-many-arguments,too-many-positional-arguments
        az_config = get_azure_config()
        with create_ssh_key(privkey_file = az_config["windows_ssh_privkey"]) as (privkey, pubkey):
            # a lot of resources have <=64 character naming constraint
            name = f"{distro}-" + str(uuid.uuid4())

            cmd = ["go", "run", "./cmd/boot-azure", "run",
                   "--subscription", az_config["subscription"],
                   "--tenant", az_config["tenant"],
                   "--client-id", az_config["client_id"],
                   "--client-secret", az_config["client_secret"],
                   "--resource-group", az_config["resource_group"],
                   "--snapshot", az_config["windows_snapshot"],
                   "--username", "azureuser",
                   "--ssh-privkey", privkey,
                   "--ssh-pubkey", pubkey,
                   "--vm-name", name,
                   "--arch", arch,
                   "--size", "Standard_D2as_v5",
                   raw_image_path, *cmd]
            testlib.runcmd_nc(cmd)


def main():
    desc = "Boot an image in the cloud environment it is built for and validate the configuration"
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("image_search_path", type=str, help="path to search for image file")

    args = parser.parse_args()
    search_path = args.image_search_path

    image_path = testlib.find_image_file(search_path)
    build_info = testlib.read_build_info(search_path)
    build_config_name = build_info["config"]
    build_config_path = f"test/configs/{build_config_name}.json"
    distro = build_info["distro"]
    arch = build_info["arch"]
    image_type = build_info["image-type"]

    print(f"Testing image at {image_path}")
    bib_image_id = ""
    # Keep test/scripts/imagetestlib.py:CAN_BOOT_TEST in sync as it
    # has the same checks again
    match image_type:
        case "qcow2" | "server-qcow2":
            boot_qemu(arch, image_path, build_config_path)
        case "image-installer" | "minimal-installer":
            boot_qemu_iso(arch, image_path, build_config_path)
        case "ami" | "ec2" | "ec2-ha" | "ec2-sap" | "edge-ami":
            boot_ami(distro, arch, image_type, image_path, build_config_path)
        case "vhd":
            boot_vhd(distro, arch, image_path, build_config_path)
        case "iot-bootable-container":
            manifest_id = build_info["manifest-checksum"]
            boot_container(distro, arch, image_type, image_path, manifest_id)
            bib_ref = testlib.get_bib_ref()
            bib_image_id = testlib.skopeo_inspect_id(f"docker://{bib_ref}", testlib.host_container_arch())
        case "wsl":
            if distro == "fedora-41":
                print(f"{distro} {image_type} boot tests are not supported, fails on wsl import")
                return
            boot_wsl(distro, arch, image_path, build_config_path)
        case _:
            # skip
            print(f"{image_type} boot tests are not supported yet")
            return

    print("âœ… Marking boot successful")
    # amend build info with boot success
    # search_path is the root of the build path (build/build_name)
    build_info["boot-success"] = True
    testlib.write_build_info(search_path, build_info)
    if bib_image_id:
        # write a separate file with the bib image ID as filename to mark the boot success with that image
        bib_id_file = os.path.join(search_path, f"bib-{bib_image_id}")
        print(f"Writing bib image ID file: {bib_id_file}")
        with open(bib_id_file, "w", encoding="utf-8") as fp:
            fp.write("")


if __name__ == "__main__":
    main()
